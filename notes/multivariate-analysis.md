# 多変量解析

<!-- HACK: 項目の並び順 -->
2つ以上の変数が相互に関連している場合に、その関連性を分析するための統計的手法です

データ間の関連性を捉えることで予測や要因分析行える。

# 多変量解析でわかる関係性
- 相関関係
- 因果関係

# 解析手法(今回扱う)
- 単変量解析
    - 相関分析：変数同士の相関を見る分析手法。影響度合いを数値化。
        - 散布図
        - ヒートマップ
    - 単回帰分析：
- 多変量解析
    - 重回帰分析

# 相関係数の特徴
- 相関係数は、-1から1の間の値をとる
- 相関係数は、絶対値が大きいほど、相関が強い
- 相関係数は
    - 正の場合：正の相関
    - 負の場合：負の相関

# 疑似相関
2つの変数間に統計的な相関が観察されるが、その相関が実際には偶然または第三の要因によるものであるという誤った結論を導くこと

# 回帰係数 vs 偏回帰係数
- 回帰係数：説明変数と目的変数の関係を表す線形モデル（単回帰分析または重回帰分析）において、説明変数と目的変数の間の単位の変化に対して、目的変数がどれだけ変化するかを表す数値。
説明変数と目的変数の間の関係を表す線の傾きを表す。
- 偏回帰係数：複数の説明変数がある多重共線性のある回帰分析において、1つの説明変数を他の説明変数が一定であると仮定したときの目的変数との関係を表す数値です。すなわち、1つの説明変数が他の説明変数の影響を受けずに、目的変数にどの程度影響を与えるかを表します。偏回帰係数は、多重共線性を考慮して回帰係数を求めるために使用する。

簡単にまとめると、回帰係数は単回帰分析や重回帰分析で説明変数と目的変数の関係を表す係数であり、偏回帰係数は多重共線性を考慮した回帰係数の一種であり、1つの説明変数が他の説明変数の影響を受けずに目的変数にどの程度影響を与えるかを表す係数

# 回帰分析を使用した検定


- ## ゼロ重み検定 (zero weight test) 
ある説明変数の重みが0であることを仮定した上で、その仮定が正しいかどうかを検定する方法。

主に変数選択のために用いられます。たとえば、複数の説明変数がある場合、モデルに含めるべき説明変数を選択する際に、ある説明変数が目的変数に対して影響を与えていないと判断された場合、その説明変数をモデルから削除することができます。


- ## ウォルド検定 (Wald test) 
説明変数の重みだけでなく、回帰係数の標準誤差も考慮に入れた検定を行うことができます

自由度調整済み決定係数 (adjusted R-squared) の改善や、回帰係数の標準誤差の算出などにも利用されます。

- ## ゼロ重み検定とウォルド検定の関係
本質的には同じものであると言えます。つまり、ゼロ重み検定はウォルド検定の特殊な場合であり、ウォルド検定はゼロ重み検定をより一般化したものと言えます。

# p値とt値
回帰分析で使用されるt値とp値は、統計的に有意な係数を特定するために使用
- t値： 係数 / 標準誤差
- p値： t値と同様に、各説明変数の係数がゼロであるかどうかを判断するために使用されます。t分布の自由度とt値を使用して、説明変数の係数がゼロである確率（つまり、帰無仮説が真である確率）を計算した値です。

# カテゴリ変数の取り扱い
- Label Encoding：カテゴリ変数を数値に変換する手法。カテゴリ変数に対して、0から始まる整数値を割り当てることで数値化します。
- One Hot Encoding：カテゴリ変数をダミー変数化する手法。、カテゴリ変数の各カテゴリを列として表し、そのカテゴリに該当する場合は1、該当しない場合は0を割り当てる方法。
※ダミー変数：0と1で表される変数

# 特徴量
分析や予測の対象となるデータの属性や特性を表す数値、カテゴリ、テキストなどの値のことを指します 